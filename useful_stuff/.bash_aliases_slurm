# save this file as ~/.bash_aliases, then add the following lines to ~/.bashrc
#
#     # Load aliases
#     if [ -f ~/.bash_aliases ]; then
#         . ~/.bash_aliases
#     fi
#

# alias qstat to show relevant information about your own jobs, sorted by job name 
alias qstat='squeue --me -o "%.18i %.9P %.32j %.8u %.8T %.10M %.6D %R" --sort=+j'

# template to transfer to your own user folder
alias ada="cd /group/pawsey0420/ada && pwd"

alias lll="ll | grep -v '\.out$'" # list files in directory exlcluding slurm log files 


# batch rename all files with name $1* to name $2*
rename_files() {
  local old_pattern="$1"
  local new_pattern="$2"
  for file in "$old_pattern"*; do
    mv "$file" "${file/$old_pattern/$new_pattern}"
  done
}

# cleanfile:  changes \r (carriage return) to \n (newline) to make slurm-TKTKTK.out files easier to read on some ssh platforms
alias cleanfile="sed -i 's|\r|\n|g'" # clean output file carriage returns for readability

# cleanout: run cleanfile every single slurm-*.out file, and put them all in an outfiles folder
# if passed a filename as an argument, open that file to the end
cleanout() {

  cleanfile slurm-[0-9]*[0-9].out

  mydir="${PWD##*/}"

  if [ $mydir != "outfiles" ]
  then

      if [ ! -d outfiles ]
      then
          mkdir outfiles
      fi
      mv slurm-[0-9]*[0-9].out outfiles/
  fi

  if [ -n "$1" ]; then
  # if passed an argument, open the file with name oe/$arg
    less +G outfiles/$1
  fi
}

alias cleanoe="cleanout"# if you use the command to sort pbs output files, run the command to sort slurm output files


parselog() {
# Find all .log files in the current working directory
# for each, save file path,final step reached, and ns/day to ./status.txt
  status_file="status.txt"
    if [[ -f "$status_file" ]]; then
       cat "$status_file" >> "${status_file%.*}_prev.${status_file##*.}"
       rm "$status_file"
    fi

  touch $status_file



  #  if [  ! -e "$status_file" ]; then
  #    echo "couldn't write to ${status_file}, instead writing to ~/jobstatus.txt"
  #    status_file="~/jobstatus.txt"
  #    touch $status_file  
  #  fi
  #
  echo "================================" >> $status_file
  date >> $status_file
  echo "================================" >> $status_file

  for file in $(find . -type f -name '*.log' -not -name '[0-9][0-9]*.log' | sort -k 1) ;do
    echo "Processing $file"

    # Add the file name to the status file
    echo $file >> $status_file
    echo >> $status_file

    # Get the last line that matches the pattern "Step           Time"
    step_time_line=$(grep -nP 'Step\s+Time' $file | tail -1 | cut -d ":" -f1)
    #echo $step_time_line
    # Add the found line, and the next line, to the status file
    #echo $(tail -2 $file | head -1) >> $status_file
    if [ -n "$step_time_line" ]; then
      sed -n "${step_time_line}p" $file >> $status_file
      sed -n "$((${step_time_line}+1))p" $file  >> $status_file
      echo >> $status_file
    fi

    # Get the last line that matches the pattern "Performance:"
    #echo $perf_line
    perf_line=$(grep -nP 'Performance:' $file | tail -1| cut -d ":" -f1)
    # Add the found line, and the preceeding line, to the status file
    if [ -n "$perf_line" ]; then
      sed -n "$((${perf_line}-1))p" $file >> $status_file
      sed -n "${perf_line}p" $file >> $status_file
    fi
    echo >> $status_file
    echo >> $status_file
  done

parsestatus $status_file

}

parsestatus () {
# parse a status.txt into a csv.
# takes the file to be parsed as an argument

    input_file=$1
    output_file="status.csv"
    date_line=""

    # Remove the output file if it already exists
    rm -f "$output_file"

    echo 'date,fname,nsteps,ns,ns per day,hour per ns' >> "$output_file"

    # Read the input file line by line
    while IFS= read -r line; do
        # Check if the line starts with "./"
        if [[ $line == ./* ]]; then
            # Extract the filename
            fname=${line#./}

            # Read the next six lines (including empty lines)
            IFS= read -r blank_line
            IFS= read -r headline1
            IFS= read -r step_line
            IFS= read -r blank_line
            IFS= read -r headline2
            IFS= read -r perf_line

            # Extract the values from the lines
            step=$(echo "$step_line" | awk '{print $1 "," $2}')
            perf=$(echo "$perf_line" | awk '{print $2 "," $3}')

            # Append the values to the output file as CSV
            echo "$date_line,$fname,$step,$perf" >> "$output_file"
        fi

        # Check if the line starts with M, T, W, F, or S
        if [[ $line =~ ^[MTWFS] ]]; then
            date_line=$line
        fi

    done < "$input_file"

}
